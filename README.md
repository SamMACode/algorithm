# 数据结构与算法之美

> 数据结构与算法是大学的基础课程，在平时开发用到的各种框架、中间件和底层系统，比如`Spring`、`RPC`框架、消息中间件、`Redis`等等。在这些基础框架中，一般都揉合了很多基础数据结构和算法的设计思想。借用争哥的话 "数据结构和算法这个东西，如果你不去学，可能这辈子真的用不到，也感受不到它的好。但是一旦掌握，你就会常常被它的强大威力所折服。"

## 复杂度分析：空间复杂度与时间复杂度

从`CPU`的角度来看，程序中每行代码的执行都是类似的操作：读数据-运算-写数据。尽管每行代码对应的`CPU`执行的个数、执行的时间都不一样。但是，只是粗略估计可以假设每行代码执行的时间都一样，为`unit_time`。可以得到规律，所有代码的执行时间`T(n)`与每行代码的执行次数`n`成正比。可以将这个规律总结为一个公式：

```
T(n) = O(f(n))
```

解释下这个公式，其中`T(n)`表示代码总的执行时间；`n`表示数据规模的大小；`f(n)`表示每行代码执行的次数总和。因为这是一个公式，所以使用函数`f(n)`表示。公式中的`O`，表示代码的执行时间与`T(n)`与`f(n)`表达式成正比。对于`T(n)=O(2n+2)`就是大`O`时间复杂度表示法。大`O`时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势。所以，也叫做渐进时间复杂度（`asymptotic time complexity`）。

几种常见时间复杂度实例分析：

* `O(1)` 一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是`O(1)`；
* `O(logn)、O(nlogn)`，`O(nlogn)` 是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 `O(nlogn)`；
* `O(m+n)、O(m*n)`，在无法评估`m`和`n`这两个数据规模时，所以我们在表示复杂度的时候，就不能简单地利用加法规则，省掉其中一个。可以使用时间复杂度`O(m+n)`来表示；

类似于时间复杂度，空间复杂度表示算法的存储空间与数据规模之间的增长关系。

```java
int find(int[] array, int length, int x) {
  int pos = -1;
  for (int i = 0; i < length; ++i) {
    if (array[i] == x) {
      pos = i;
      break;
    }
  }
  return pos;
}
```

函数`find`用于在数组中根据`x`找到其在`array`中的下标位置，元素`x`在数组中位置是任意的。当`x`是位于数组的第一个元素，则只需遍历一次就可以，剩余的`n-1`个元素不用再遍历，时间复杂度为`O(1)`。若`x`不再数组中，则需要遍历数组中所有的元素，时间度就变为了`O(n)`。这就引入了**最好情况时间复杂度**、**最坏情况时间复杂度** 的概念。

## 线性表结构：数组、链表、队列、栈

数组（`array`）是一种线性表数据结构，它使用一组连续的内存空间，来存储一组具有相同类型的数据。线性表（`linear list`）就是数据拍成像一条线一样的结构，每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

```
a[i]_address = base_address + i * data_type_size;
```

对于数组类型中，计算机会分配一段连续的内存空间。例如内存块的首地址为`base_address = 1000`，访问元素内存可根				据`base_address`、要访问的下标、`type`占据字节数计算要访问的下标数据。关于数组下标为什么从`0`开始的解释是：如果数组从 1 开始计数，那我们计算数组元素`a[k]`的内存地址就会变为`a[k]_address = base_address + (k-1)*type_size`，每次随机访问数组都多了一次减法运算，对于`CPU`来说就是多了一次减法指令。

用链表实现`LRU`算法思路，维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历：

1）如果数据之前已经缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部；

2）若此数据没有缓存在链表中，又可以分为两种情况：

* 要是缓存未满，则直接将此结点插入到链表的头部；
* 缓存空间已满，则链表尾部节点删除，将新的数据结点插入到链表的头部；

优化：不论缓存有没有满，我们都要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度是`O(n)`。可以引入散列表`HashTable`来记录每个元素的位置，将缓存访问的时间复杂度降低到`O(1)`。

后进者先出，先进者后出，这就是典型的"栈"结构。从操作上来看，栈是一种"操作受限"的线性表，只允许在一段插入和删除元素。

**栈在函数调用中应用**，比较经典的一个应用场景就是函数调用栈。操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成"栈"这种数据结构，用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

**栈在表达式求值中的应用**，比如`34 + 13*9 + 44 - 12/3`这个表达式的四则运算，编译器就是通过两个栈来实现的。其中一个是保存操作数的栈，另一个是保存运算符的栈。我们从左向右扫描表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。

逻辑，如果比运算符栈顶元素的优先级高，就将当前运算符压入栈。如果比运算符栈顶元素的优先级级低或相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取`2`个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

**栈在括号匹配中的应用**，除了使用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。当扫描到左括号时，将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。若能够匹配，比如"`(`"跟"`)`"匹配，"`{`"与"`}`"匹配，则继续扫描剩下的字符串。如果扫描过程中，遇到不能配对的右括号，或者栈中没有数据，则说明是非法格式。

当所有的括号都扫描完成之后，若堆栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。

问题思考🤗：

1）我们在讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？不一定非得用栈保存临时变量，其只是符合后进先出的特点。

2）JVM 内存管理中有个“堆栈”的概念。栈内存用来存储局部变量和方法调用，堆内存用来存储 Java 中的对象。那 JVM 里面的“栈”跟我们这里说的“栈”是不是一回事呢？如果不是，那它为什么又叫作“栈”呢？不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。

**queue队列再线程池等有限资源池中的应用**，队列主要提供 压入元素`enqueue(item)` 与 弹出元素`dequeue() 2`种操作。线程安全的队列我们叫做并发队列，最简单直接的方式是直接在`enqueue()、dequeue()`方法上加锁。基于数组的循环队列（避免大范围移动元素），利用`CAS`原子操作，可以实现非常高效的并发队列。 

问题思考🤔：

1）除了线程池这种池结构会用到队列排队请求，你还知道有哪些类似的池结构或者场景中会用到队列的排队请求呢？分布式应用中的消息队列

2）今天讲到并发队列，关于如何实现无锁并发队列，网上有非常多的讨论。对这个问题，你怎么看呢？考虑使用`CAS`实现无锁队列，在入队前获取`tail`位置，入队时比较`tail`是否发生变化，若未变化 则允许入队列 否则，入队列失败，出队列获取`head`位置进行`cas`。

## 散列表和hash算法

思考一个问题，`word`文档中的单词拼接功能是如何实现的？`hashtable`散列表对`word`中的单词进行`hash`构成哈希表，然后可判断字符是否已经在`hash`表中，来校验输入是否合法。

散列表的优势在使用数组支持下标随机访问的特性（常数时间），所以散列表其实就是数组的一种扩展，由数组演化而来。散列函数在散列表中起着非常关键的作用。顾名思义`hash(key)`中`key`表示元素的键值，`hash(key)`的值表示经过散列函数计算得到的数值。

`hash()`函数的准则：散列函数计算到的散列值是一个非负数、若`key1 = key2` 那么`hash(key1) == hash(key2)`、当`key1 != key2` 则`hash(key1) != hash(key2)`。实际存在`hash`冲突问题，即使像`MD5`、`SHA`、`CRC`等哈希算法也无法避免。

`hash()`冲突如何解决？常用开放寻址法（`open addressing`）及链表法（`chaining`）。思路：当某数据经过`hash(key)`后，但存储位置已经被占用了，我们从当前位置开始依次往后找，直到找到空闲位置。存在饱和度问题，存储元素/可存储元素（装载因子）比例不能太高，否则容易造成`hash`冲突。解决开放寻址冲突方案有二次探测（`Quadratic probing`）和双重散列（`Double hashing`）方式。

链表法是将`hash`值相同的元素放入同一个`slot`中，各个元素使用链表进行串联。`hash()`函数执行为常数时间完成，查找元素在线性时间完成。

问题思考🤔：

1）假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？遍历`10`万条数据，以`URL`为`key`访问次数为`value`，存入散列表中，同时记录下访问次数`K`，时间复杂度`O(N)`。

2）有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？以第一个字符串数组构建散列表，`key`为字符串，`value`为出现的次数。再遍历第二个字符串数组，以字符串`key`在散列表中查找，若`value`大于`0` 则存在相同字符串，复杂度为`O(N)`。

工业级的`hash`表应支持初始化大小、装载因子和动态扩容，链表长度超过`8`优化为红黑树。扩容效率低问题，所有元素需要重新计算`HASH`值。（方案）装载因子到达阀值后，每将一个元素插入时，从旧的散列表中拿出一个数据放入新散列表中，同时维护两个`HASH`表。

将任意长度的二进制值串映射为固定长度的二进制串，这个映射的规则就是`HASH`算法，而通过原始数据映射之后得到的二进制串就是`HASH`值。有几点要求，从哈希值不能反向推导出原始数据（哈希算法是单向的）、对输入数据非常敏感及冲突概率小、执行尽量高效，针对较长的文本，也能快速地计算出`HASH`值。

可应用在安全加密领域`MD5`和`SHA`算法、唯一标识逻辑、数据校验（`P2P`下载、`CRC`校验码 `TCP、IP`数据报完整性验证）、散列函数、负载均衡（轮询、加权、随机查询）、数据分片（对数据进行分片，然后采用多台机器处理的方法，来提高处理速度 `HASH`算法取余）等方面。

## 跳表：redis使用跳表实现有序集合

`Redis`中的有序集合是使用跳表（`Sorted Set`）实现的，对于一个单链表来讲，即便链表中存储的数据是有序的，想在其中找某个数据，也只能从头到尾遍历链表，其时间复杂度尾`O(n)`。

通过对链表加多层索引结构，以实现快速访问链表元素，这种数据结构称为跳表。时间复杂度 第`k` 级索引的结点个数是第`k-1`级索引的结点个数的`1/2`，那第`k`级索引结点的个数就是`n/(2k次方)`。

比起单纯的单链表，跳表需要存储多级索引，肯定要消耗更多的存储空间。那到底需要消耗多少额外的存储空间呢？

若每`2`个节点抽取一个索引，这几级索引的结点总和就是 `n/2+n/4+n/8…+8+4+2=n-2`。所以，跳表的空间复杂度是 `O(n)`。也就是说，如果将包含 `n` 个结点的单链表构造成跳表，我们需要额外再用接近 `n` 个结点的存储空间。为降低空间复杂度，可以使用每`n`个结点抽取一个索引结点。

😨思考，`redis`中的有序集合使用跳表实现，严格来说其实还用到了散列表。对于按区间查找数据的操作，跳表可以做到`O(log n)`的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以。效率非常高，相对于红黑树来说。



